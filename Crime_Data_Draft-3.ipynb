{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qfX7xlmhWZ8"
      },
      "source": [
        "import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xK2oGY6NhVie"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVK8XMB0hw_k",
        "outputId": "6ca4d023-620d-4663-f8f4-19c464995e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGwBAu3UiAUd"
      },
      "source": [
        "Read File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8MMnccLh96x"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/crime1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "NDUEHlu2iCNB",
        "outputId": "a144f457-80d4-45b1-e05b-cd4b6110e3f2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f3b07460-57b6-422d-ac6e-3abe56b2a074\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crime_id</th>\n",
              "      <th>report_num</th>\n",
              "      <th>address</th>\n",
              "      <th>offense_de</th>\n",
              "      <th>offense_ca</th>\n",
              "      <th>state_offe</th>\n",
              "      <th>arrest_cha</th>\n",
              "      <th>charge_des</th>\n",
              "      <th>incident_t</th>\n",
              "      <th>day_of_wee</th>\n",
              "      <th>...</th>\n",
              "      <th>scout_car_</th>\n",
              "      <th>precinct</th>\n",
              "      <th>block_id</th>\n",
              "      <th>Cities</th>\n",
              "      <th>council_di</th>\n",
              "      <th>zip_code</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>ibr_date</th>\n",
              "      <th>oid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3021501</td>\n",
              "      <td>1702050013</td>\n",
              "      <td>W Chicago St &amp; Carlin Ave</td>\n",
              "      <td>ARSON</td>\n",
              "      <td>ARSON</td>\n",
              "      <td>2099</td>\n",
              "      <td>20000</td>\n",
              "      <td>ARSON</td>\n",
              "      <td>2/5/17</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0207</td>\n",
              "      <td>02</td>\n",
              "      <td>261635351002016</td>\n",
              "      <td>Plymouth-Hubbell</td>\n",
              "      <td>7</td>\n",
              "      <td>48227</td>\n",
              "      <td>-83.178905</td>\n",
              "      <td>42.365775</td>\n",
              "      <td>5/15/17</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3046060</td>\n",
              "      <td>1704040001</td>\n",
              "      <td>Cass Ave &amp; W Canfield St</td>\n",
              "      <td>ARSON</td>\n",
              "      <td>ARSON</td>\n",
              "      <td>2099</td>\n",
              "      <td>20000</td>\n",
              "      <td>ARSON</td>\n",
              "      <td>4/4/17</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0309</td>\n",
              "      <td>03</td>\n",
              "      <td>261635203001000</td>\n",
              "      <td>Midtown</td>\n",
              "      <td>6</td>\n",
              "      <td>48201</td>\n",
              "      <td>-83.064139</td>\n",
              "      <td>42.351578</td>\n",
              "      <td>1/16/18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3049686</td>\n",
              "      <td>1704110374</td>\n",
              "      <td>Margareta St &amp; Oak Dr</td>\n",
              "      <td>TRESPASS</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>5701</td>\n",
              "      <td>57001</td>\n",
              "      <td>TRESPASS</td>\n",
              "      <td>4/12/17</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1209</td>\n",
              "      <td>12</td>\n",
              "      <td>261635384001009</td>\n",
              "      <td>University District</td>\n",
              "      <td>2</td>\n",
              "      <td>48221</td>\n",
              "      <td>-83.138532</td>\n",
              "      <td>42.428059</td>\n",
              "      <td>5/15/17</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3056001</td>\n",
              "      <td>1704270155</td>\n",
              "      <td>Peters St &amp; S Ethel St</td>\n",
              "      <td>FRAUD - IMPERSONATION</td>\n",
              "      <td>FRAUD</td>\n",
              "      <td>2603</td>\n",
              "      <td>26003</td>\n",
              "      <td>FRAUD - IMPERSONATION</td>\n",
              "      <td>4/23/17</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0415</td>\n",
              "      <td>04</td>\n",
              "      <td>261635248002001</td>\n",
              "      <td>Boynton</td>\n",
              "      <td>6</td>\n",
              "      <td>48217</td>\n",
              "      <td>-83.158897</td>\n",
              "      <td>42.259713</td>\n",
              "      <td>5/15/17</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3205123</td>\n",
              "      <td>1804300085</td>\n",
              "      <td>S M 39 Service Drive &amp; Joy Rd</td>\n",
              "      <td>ROBBERY</td>\n",
              "      <td>ROBBERY</td>\n",
              "      <td>1201</td>\n",
              "      <td>12000</td>\n",
              "      <td>ROBBERY</td>\n",
              "      <td>4/28/18</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0610</td>\n",
              "      <td>06</td>\n",
              "      <td>261635460001000</td>\n",
              "      <td>Warrendale</td>\n",
              "      <td>7</td>\n",
              "      <td>48228</td>\n",
              "      <td>-83.216912</td>\n",
              "      <td>42.357846</td>\n",
              "      <td>5/1/18</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3b07460-57b6-422d-ac6e-3abe56b2a074')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3b07460-57b6-422d-ac6e-3abe56b2a074 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3b07460-57b6-422d-ac6e-3abe56b2a074');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fe12966c-b533-4719-882a-b9db200f20bd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe12966c-b533-4719-882a-b9db200f20bd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fe12966c-b533-4719-882a-b9db200f20bd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   crime_id  report_num                        address             offense_de  \\\n",
              "0   3021501  1702050013      W Chicago St & Carlin Ave                  ARSON   \n",
              "1   3046060  1704040001       Cass Ave & W Canfield St                  ARSON   \n",
              "2   3049686  1704110374          Margareta St & Oak Dr               TRESPASS   \n",
              "3   3056001  1704270155         Peters St & S Ethel St  FRAUD - IMPERSONATION   \n",
              "4   3205123  1804300085  S M 39 Service Drive & Joy Rd                ROBBERY   \n",
              "\n",
              "  offense_ca  state_offe arrest_cha             charge_des incident_t  \\\n",
              "0      ARSON        2099      20000                  ARSON     2/5/17   \n",
              "1      ARSON        2099      20000                  ARSON     4/4/17   \n",
              "2      OTHER        5701      57001               TRESPASS    4/12/17   \n",
              "3      FRAUD        2603      26003  FRAUD - IMPERSONATION    4/23/17   \n",
              "4    ROBBERY        1201      12000                ROBBERY    4/28/18   \n",
              "\n",
              "   day_of_wee  ...  scout_car_  precinct         block_id  \\\n",
              "0           7  ...        0207        02  261635351002016   \n",
              "1           2  ...        0309        03  261635203001000   \n",
              "2           2  ...        1209        12  261635384001009   \n",
              "3           7  ...        0415        04  261635248002001   \n",
              "4           5  ...        0610        06  261635460001000   \n",
              "\n",
              "                Cities  council_di zip_code  longitude   latitude  ibr_date  \\\n",
              "0     Plymouth-Hubbell           7    48227 -83.178905  42.365775   5/15/17   \n",
              "1              Midtown           6    48201 -83.064139  42.351578   1/16/18   \n",
              "2  University District           2    48221 -83.138532  42.428059   5/15/17   \n",
              "3              Boynton           6    48217 -83.158897  42.259713   5/15/17   \n",
              "4           Warrendale           7    48228 -83.216912  42.357846    5/1/18   \n",
              "\n",
              "   oid  \n",
              "0    1  \n",
              "1    2  \n",
              "2    3  \n",
              "3    4  \n",
              "4    5  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4sqswL1qiRtM"
      },
      "outputs": [],
      "source": [
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp_BVQ43iU3_",
        "outputId": "ef03ba66-3a70-4f41-b9c3-5c5b66b21598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 531979 entries, 0 to 531998\n",
            "Data columns (total 22 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   crime_id    531979 non-null  int64  \n",
            " 1   report_num  531979 non-null  int64  \n",
            " 2   address     531979 non-null  object \n",
            " 3   offense_de  531979 non-null  object \n",
            " 4   offense_ca  531979 non-null  object \n",
            " 5   state_offe  531979 non-null  int64  \n",
            " 6   arrest_cha  531979 non-null  object \n",
            " 7   charge_des  531979 non-null  object \n",
            " 8   incident_t  531979 non-null  object \n",
            " 9   day_of_wee  531979 non-null  int64  \n",
            " 10  hour_of_da  531979 non-null  int64  \n",
            " 11  year        531979 non-null  int64  \n",
            " 12  scout_car_  531979 non-null  object \n",
            " 13  precinct    531979 non-null  object \n",
            " 14  block_id    531979 non-null  int64  \n",
            " 15  Cities      531979 non-null  object \n",
            " 16  council_di  531979 non-null  int64  \n",
            " 17  zip_code    531979 non-null  int64  \n",
            " 18  longitude   531979 non-null  float64\n",
            " 19  latitude    531979 non-null  float64\n",
            " 20  ibr_date    531979 non-null  object \n",
            " 21  oid         531979 non-null  int64  \n",
            "dtypes: float64(2), int64(10), object(10)\n",
            "memory usage: 93.3+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXVD5nxOieb7"
      },
      "outputs": [],
      "source": [
        "#data['incident_t'] = pd.to_datetime(data['incident_t'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ1bER2Wihjr"
      },
      "outputs": [],
      "source": [
        "#data['day'] = data['incident_t'].dt.day\n",
        "#data['month'] = data['incident_t'].dt.month\n",
        "#data['year'] = data['incident_t'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V6ZhGM4itZs",
        "outputId": "6c2a9847-3dfd-46d1-8e0b-d8d761f6db45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "offense_ca\n",
              "ASSAULT                   96724\n",
              "LARCENY                   79206\n",
              "DAMAGE TO PROPERTY        68860\n",
              "AGGRAVATED ASSAULT        54941\n",
              "STOLEN VEHICLE            47357\n",
              "FRAUD                     42391\n",
              "BURGLARY                  40910\n",
              "WEAPONS OFFENSES          19457\n",
              "ROBBERY                   12605\n",
              "DANGEROUS DRUGS           10261\n",
              "STOLEN PROPERTY           10178\n",
              "SEX OFFENSES               7419\n",
              "OBSTRUCTING JUDICIARY      7208\n",
              "OBSTRUCTING THE POLICE     5368\n",
              "SEXUAL ASSAULT             4834\n",
              "ARSON                      4381\n",
              "OUIL                       3386\n",
              "FAMILY OFFENSE             2837\n",
              "RUNAWAY                    2568\n",
              "MISCELLANEOUS              2242\n",
              "HOMICIDE                   1859\n",
              "DISORDERLY CONDUCT         1766\n",
              "OTHER                      1547\n",
              "FORGERY                    1493\n",
              "KIDNAPPING                 1227\n",
              "LIQUOR                      488\n",
              "EXTORTION                   292\n",
              "JUSTIFIABLE HOMICIDE        130\n",
              "SOLICITATION                 34\n",
              "GAMBLING                     10\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['offense_ca'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvP5FskbH8Ko",
        "outputId": "7856ad61-f126-43e2-8b60-517fc2f0632f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "531979"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['offense_ca'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou2IpA-6GxRY"
      },
      "outputs": [],
      "source": [
        "data = data[['offense_ca','day_of_wee','hour_of_da','Cities','council_di','zip_code']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDOGfbtAVO7_"
      },
      "outputs": [],
      "source": [
        "def change_label(df):\n",
        "    df.offense_ca.replace(['ASSAULT','AGGRAVATED ASSAULT', 'ROBBERY', 'SEXUAL ASSAULT', 'HOMICIDE', 'JUSTIFIABLE HOMICIDE', 'KIDNAPPING', 'ARSON'], 'ViolentCrime', inplace=True)\n",
        "    df.offense_ca.replace(['LARCENY', 'DAMAGE TO PROPERTY', 'BURGLARY', 'STOLEN VEHICLE', 'STOLEN PROPERTY', 'FRAUD', 'FORGERY'], 'PropertyCrime', inplace=True)\n",
        "    df.offense_ca.replace(['DANGEROUS DRUGS', 'WEAPONS OFFENSES', 'OBSTRUCTING JUDICIARY', 'OBSTRUCTING THE POLICE', 'DISORDERLY CONDUCT', 'FAMILY OFFENSE', 'RUNAWAY', 'MISCELLANEOUS', 'OTHER'], 'DrugsCrime', inplace=True)\n",
        "    df.offense_ca.replace(['OUIL','SEX OFFENSES','LIQUOR', 'EXTORTION', 'SOLICITATION', 'GAMBLING'], 'MiscCrime', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6MzIsTlVRNX"
      },
      "outputs": [],
      "source": [
        "change_label(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW4xYtQGVVm1",
        "outputId": "a5c797b1-6ed3-44a8-ba5c-2ac9ca6d2560"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "offense_ca\n",
              "PropertyCrime    290395\n",
              "ViolentCrime     176701\n",
              "DrugsCrime        53254\n",
              "MiscCrime         11629\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['offense_ca'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r0pGtDjVbtq",
        "outputId": "92e3f783-1417-4ba1-9a00-2d095f13bd56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 531979 entries, 0 to 531998\n",
            "Data columns (total 6 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   offense_ca  531979 non-null  object\n",
            " 1   day_of_wee  531979 non-null  int64 \n",
            " 2   hour_of_da  531979 non-null  int64 \n",
            " 3   Cities      531979 non-null  object\n",
            " 4   council_di  531979 non-null  int64 \n",
            " 5   zip_code    531979 non-null  int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 28.4+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OWUO5j7H6hk"
      },
      "outputs": [],
      "source": [
        "# Convert column 'A' to string\n",
        "#data['precinct'] = data['precinct'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqMOZo6YDgfF",
        "outputId": "7080cee0-0c25-4939-b6fb-79e198b78017"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "offense_ca    531979\n",
              "day_of_wee    531979\n",
              "hour_of_da    531979\n",
              "Cities        531979\n",
              "council_di    531979\n",
              "zip_code      531979\n",
              "dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#import pandas as pd\n",
        "# Create a new DataFrame without the rows where the column has the specified value\n",
        "#data = data[~data['zip_code'].isin([48236, 48238, 48239, 48243])]\n",
        "data.count()\n",
        "#data['offense_ca'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbwvm39DV-pb"
      },
      "source": [
        "preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cTrZsdnGx76"
      },
      "outputs": [],
      "source": [
        "data.to_csv('/content/drive/MyDrive/reduced_set.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKkItzvUJfra"
      },
      "outputs": [],
      "source": [
        "data = data[~((data['zip_code'].isin([48201, 48202, 48203, 48203, 48204, 48205])) & (data['offense_ca'].isin(['DrugsCrime','PropertyCrime'])))]\n",
        "data = data[~((data['zip_code'].isin([48206, 48207, 48208, 48209, 48210, 48211])) & (data['offense_ca'].isin(['PropertyCrime','ViolentCrime'])))]\n",
        "data = data[~((data['zip_code'].isin([48212, 48213, 48214, 48215])) & (data['offense_ca'].isin(['DrugsCrime','ViolentCrime'])))]\n",
        "data = data[~((data['zip_code'].isin([48216, 48217, 48219, 48221,48223])) & (data['offense_ca'].isin(['PropertyCrime'])))]\n",
        "data = data[~((data['zip_code'].isin([48224, 48226, 48227, 48228])) & (data['offense_ca'].isin(['DrugsCrime','ViolentCrime'])))]\n",
        "data = data[~((data['zip_code'].isin([48234, 48235])) & (data['offense_ca'].isin(['ViolentCrime','PropertyCrime'])))]\n",
        "data = data[~((data['zip_code'].isin([48236, 48238, 48239, 48243])) & (data['offense_ca'].isin(['ViolentCrime','PropertyCrime'])))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvEimj7MwfyL",
        "outputId": "ae91dc8e-f2ec-4746-e308-a8cc5569b214"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "offense_ca    190620\n",
              "day_of_wee    190620\n",
              "hour_of_da    190620\n",
              "Cities        190620\n",
              "council_di    190620\n",
              "zip_code      190620\n",
              "dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNmOKm290SXt",
        "outputId": "1e9afeec-9d2f-4743-addb-22ac9d18816f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "offense_ca\n",
              "PropertyCrime    96373\n",
              "ViolentCrime     59136\n",
              "DrugsCrime       23482\n",
              "MiscCrime        11629\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['offense_ca'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bJnrbmZV1-_"
      },
      "outputs": [],
      "source": [
        "# prompt: suggest a model that gives good accuracy for the data in dataframe\n",
        "from sklearn import preprocessing\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "label_encoder_off_ca = preprocessing.LabelEncoder()\n",
        "\n",
        "\n",
        "# Encode labels in column 'species'.\n",
        "data['offense_ca']= label_encoder_off_ca.fit_transform(data['offense_ca'])\n",
        "#data['zip_code']= label_encoder.fit_transform(data['zip_code'])\n",
        "data['day_of_wee']= label_encoder.fit_transform(data['day_of_wee'])\n",
        "data['hour_of_da']= label_encoder.fit_transform(data['hour_of_da'])\n",
        "#scout_car_= label_encoder.fit_transform(data['scout_car_'])\n",
        "#data['precinct']= label_encoder.fit_transform(data['precinct'])\n",
        "data['Cities'] = label_encoder.fit_transform(data['Cities'])\n",
        "data['council_di']= label_encoder.fit_transform(data['council_di'])\n",
        "data['zip_code']= label_encoder.fit_transform(data['zip_code'])\n",
        "\n",
        "\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('offense_ca', axis=1)\n",
        "y = data['offense_ca']\n",
        "\n",
        "# Get the categories associated with each label encoder value for each column\n",
        "categories_offense_ca = label_encoder_off_ca.classes_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t12OQpTfvtwN",
        "outputId": "d5ade805-814b-4172-f763-7e5323981cca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "offense_ca    190620\n",
              "day_of_wee    190620\n",
              "hour_of_da    190620\n",
              "Cities        190620\n",
              "council_di    190620\n",
              "zip_code      190620\n",
              "dtype: int64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXKuhbh4V63f"
      },
      "source": [
        "Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQTlHC209oGj",
        "outputId": "bb5a6d4d-c9d8-4717-fc66-c3239964af19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['DrugsCrime' 'MiscCrime' 'PropertyCrime' 'ViolentCrime']\n"
          ]
        }
      ],
      "source": [
        "print(categories_offense_ca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YffC5u-cV6gx"
      },
      "outputs": [],
      "source": [
        "# Split data into training and test sets\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "# Split data into training, validation, and test sets\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # x_train_full = 80 x_test = 20\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "# x_train 72 x_val 8\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrBdc3GTxriX",
        "outputId": "958ccf2a-b422-4a3d-dc01-a13b7b2a4df1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "day_of_wee    137246\n",
              "hour_of_da    137246\n",
              "Cities        137246\n",
              "council_di    137246\n",
              "zip_code      137246\n",
              "dtype: int64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.count()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AACdJDANyCIb",
        "outputId": "12e6712f-c8d1-475b-ad8f-01c1d981dd61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "day_of_wee    15250\n",
              "hour_of_da    15250\n",
              "Cities        15250\n",
              "council_di    15250\n",
              "zip_code      15250\n",
              "dtype: int64"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_val.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDdsE4tFyCdg",
        "outputId": "db74c2cb-4248-4a17-e33c-5e82b4a53b68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "day_of_wee    38124\n",
              "hour_of_da    38124\n",
              "Cities        38124\n",
              "council_di    38124\n",
              "zip_code      38124\n",
              "dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVM0TnSDxotG"
      },
      "outputs": [],
      "source": [
        "# Ensure the data is in the correct format if needed\n",
        "X_train = X_train.values\n",
        "X_val = X_val.values\n",
        "X_test = X_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQMB8WkYVwf7",
        "outputId": "6a86296f-6a46-4c0a-b11d-7512967bd848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN with k=3\n",
            "Cross-validation scores: [0.8820765  0.87944916 0.88189005 0.88305585 0.88156217]\n",
            "Mean cross-validation score: 0.8816067465007634\n",
            "Validation Accuracy: 0.8864262295081967\n",
            "Test Data Accuracy: 0.8797870108068409\n",
            "Test Accuracy: 0.88\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.67      0.69      4741\n",
            "           1       0.42      0.24      0.30      2369\n",
            "           2       0.97      0.99      0.98     19169\n",
            "           3       0.85      0.92      0.89     11845\n",
            "\n",
            "    accuracy                           0.88     38124\n",
            "   macro avg       0.74      0.70      0.71     38124\n",
            "weighted avg       0.87      0.88      0.87     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 3161   284     8  1288]\n",
            " [  562   560   665   582]\n",
            " [    2   234 18933     0]\n",
            " [  710   245     3 10887]]\n",
            "KNN with k=5\n",
            "Cross-validation scores: [0.88998179 0.89030566 0.89241867 0.89340231 0.89096142]\n",
            "Mean cross-validation score: 0.8914139678546755\n",
            "Validation Accuracy: 0.8964590163934426\n",
            "Test Data Accuracy: 0.8890462700661\n",
            "Test Accuracy: 0.89\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.67      0.71      4741\n",
            "           1       0.52      0.23      0.32      2369\n",
            "           2       0.96      0.99      0.98     19169\n",
            "           3       0.85      0.94      0.89     11845\n",
            "\n",
            "    accuracy                           0.89     38124\n",
            "   macro avg       0.77      0.71      0.72     38124\n",
            "weighted avg       0.87      0.89      0.88     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 3188   204    13  1336]\n",
            " [  570   539   673   587]\n",
            " [    0   109 19058     2]\n",
            " [  538   191     7 11109]]\n",
            "KNN with k=7\n",
            "Cross-validation scores: [0.89526412 0.89449525 0.89671755 0.8964261  0.89427666]\n",
            "Mean cross-validation score: 0.895435933810947\n",
            "Validation Accuracy: 0.9008524590163934\n",
            "Test Data Accuracy: 0.8927709579267653\n",
            "Test Accuracy: 0.89\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.67      0.71      4741\n",
            "           1       0.57      0.22      0.31      2369\n",
            "           2       0.96      1.00      0.98     19169\n",
            "           3       0.85      0.95      0.90     11845\n",
            "\n",
            "    accuracy                           0.89     38124\n",
            "   macro avg       0.79      0.71      0.73     38124\n",
            "weighted avg       0.88      0.89      0.88     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 3169   162    23  1387]\n",
            " [  577   513   687   592]\n",
            " [    0    82 19085     2]\n",
            " [  423   141    12 11269]]\n",
            "KNN with k=9\n",
            "Cross-validation scores: [0.89872495 0.89679041 0.89755547 0.89788335 0.89744617]\n",
            "Mean cross-validation score: 0.8976800704947031\n",
            "Validation Accuracy: 0.9024262295081967\n",
            "Test Data Accuracy: 0.8954464379393557\n",
            "Test Accuracy: 0.90\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.67      0.72      4741\n",
            "           1       0.61      0.21      0.32      2369\n",
            "           2       0.96      1.00      0.98     19169\n",
            "           3       0.85      0.96      0.90     11845\n",
            "\n",
            "    accuracy                           0.90     38124\n",
            "   macro avg       0.80      0.71      0.73     38124\n",
            "weighted avg       0.88      0.90      0.88     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 3158   132    27  1424]\n",
            " [  574   508   682   605]\n",
            " [    2    70 19095     2]\n",
            " [  326   129    13 11377]]\n",
            "KNN with k=11\n",
            "Cross-validation scores: [0.89919854 0.89602536 0.89832052 0.89868483 0.89711829]\n",
            "Mean cross-validation score: 0.8978695092823579\n",
            "Validation Accuracy: 0.9027540983606558\n",
            "Test Data Accuracy: 0.8959710418633932\n",
            "Test Accuracy: 0.90\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.66      0.72      4741\n",
            "           1       0.63      0.21      0.31      2369\n",
            "           2       0.96      1.00      0.98     19169\n",
            "           3       0.85      0.97      0.90     11845\n",
            "\n",
            "    accuracy                           0.90     38124\n",
            "   macro avg       0.81      0.71      0.73     38124\n",
            "weighted avg       0.88      0.90      0.88     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 3138   108    31  1464]\n",
            " [  573   488   690   618]\n",
            " [    4    63 19100     2]\n",
            " [  279   119    15 11432]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report,confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "# Create KNN classifier with k=3,5,7,9,11\n",
        "n_neighbors = [3,5,7,9,11]\n",
        "for i in n_neighbors:\n",
        "  print(f\"KNN with k={i}\")\n",
        "  knn = KNeighborsClassifier(n_neighbors=i)\n",
        "  # Perform cross-validation with 5 folds\n",
        "  cv_scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
        "  # Print the cross-validation scores\n",
        "  print(\"Cross-validation scores:\", cv_scores)\n",
        "  print(\"Mean cross-validation score:\", np.mean(cv_scores))\n",
        "  # Fit the model on the training data\n",
        "  knn.fit(X_train, y_train)\n",
        "  # Predict on the validation data\n",
        "  y_val_pred = knn.predict(X_val)\n",
        "  val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "  print(\"Validation Accuracy:\", val_accuracy)\n",
        "  # Predict the labels for test set\n",
        "  y_pred = knn.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(\"Test Data Accuracy:\", accuracy)\n",
        "  test_class_report = classification_report(y_test, y_pred)\n",
        "  test_conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "  print(\"Test Classification Report:\")\n",
        "  print(test_class_report)\n",
        "  print(\"Test Confusion Matrix:\")\n",
        "  print(test_conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRkd-X3TDijf",
        "outputId": "be272069-2c0a-414f-a35f-3d8e64149a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Logistic regression\n",
            "Cross-validation scores: [0.72466302 0.72294073 0.72264928 0.72461656 0.722795  ]\n",
            "Mean cross-validation score: 0.7235329180442006\n",
            "\n",
            "Model: Logistic Regression\n",
            "Validation Accuracy: 0.74\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.02      0.04      1819\n",
            "           1       0.00      0.00      0.00       928\n",
            "           2       0.75      0.93      0.83      7789\n",
            "           3       0.72      0.84      0.78      4714\n",
            "\n",
            "    accuracy                           0.74     15250\n",
            "   macro avg       0.43      0.45      0.41     15250\n",
            "weighted avg       0.63      0.74      0.67     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[  40    0 1133  646]\n",
            " [  17    0  504  407]\n",
            " [ 112    0 7230  447]\n",
            " [   7    0  767 3940]]\n",
            "\n",
            "Test Accuracy: 0.73\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.02      0.04      4741\n",
            "           1       0.00      0.00      0.00      2369\n",
            "           2       0.74      0.92      0.82     19169\n",
            "           3       0.72      0.84      0.78     11845\n",
            "\n",
            "    accuracy                           0.73     38124\n",
            "   macro avg       0.42      0.45      0.41     38124\n",
            "weighted avg       0.62      0.73      0.66     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[   92     0  2980  1669]\n",
            " [   36     0  1305  1028]\n",
            " [  316     0 17721  1132]\n",
            " [   20     0  1893  9932]]\n",
            "Model: Logistic regression\n",
            "Cross-validation scores: [0.67344262 0.66916828 0.67142701 0.67208277 0.67160917]\n",
            "Mean cross-validation score: 0.6715459693058186\n",
            "\n",
            "Model: Logistic Regression\n",
            "Validation Accuracy: 0.68\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.07      0.00      0.01      1819\n",
            "           1       0.00      0.00      0.00       928\n",
            "           2       0.66      0.97      0.79      7789\n",
            "           3       0.76      0.61      0.68      4714\n",
            "\n",
            "    accuracy                           0.68     15250\n",
            "   macro avg       0.37      0.39      0.37     15250\n",
            "weighted avg       0.58      0.68      0.61     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[   6    0 1441  372]\n",
            " [   6    0  579  343]\n",
            " [  68    0 7534  187]\n",
            " [   4    0 1840 2870]]\n",
            "\n",
            "Test Accuracy: 0.68\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.04      0.00      0.00      4741\n",
            "           1       0.00      0.00      0.00      2369\n",
            "           2       0.65      0.96      0.78     19169\n",
            "           3       0.76      0.62      0.69     11845\n",
            "\n",
            "    accuracy                           0.68     38124\n",
            "   macro avg       0.37      0.40      0.37     38124\n",
            "weighted avg       0.57      0.68      0.61     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[   11     0  3779   951]\n",
            " [    9     0  1502   858]\n",
            " [  215     0 18476   478]\n",
            " [   16     0  4459  7370]]\n",
            "Model: Logistic regression\n",
            "Cross-validation scores: [0.5932969  0.58847317 0.58359139 0.59109621 0.58978469]\n",
            "Mean cross-validation score: 0.5892484731909835\n",
            "\n",
            "Model: Logistic Regression\n",
            "Validation Accuracy: 0.58\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.28      0.24      1819\n",
            "           1       0.00      0.00      0.00       928\n",
            "           2       0.62      0.85      0.72      7789\n",
            "           3       0.79      0.36      0.50      4714\n",
            "\n",
            "    accuracy                           0.58     15250\n",
            "   macro avg       0.41      0.37      0.36     15250\n",
            "weighted avg       0.59      0.58      0.55     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[ 508    0 1182  129]\n",
            " [ 136    0  551  241]\n",
            " [1073    0 6630   86]\n",
            " [ 753    0 2247 1714]]\n",
            "\n",
            "Test Accuracy: 0.57\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.27      0.23      4741\n",
            "           1       0.00      0.00      0.00      2369\n",
            "           2       0.61      0.85      0.71     19169\n",
            "           3       0.79      0.37      0.51     11845\n",
            "\n",
            "    accuracy                           0.57     38124\n",
            "   macro avg       0.40      0.37      0.36     38124\n",
            "weighted avg       0.58      0.57      0.54     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 1262     0  3104   375]\n",
            " [  319     0  1482   568]\n",
            " [ 2681     0 16238   250]\n",
            " [ 1811     0  5628  4406]]\n"
          ]
        }
      ],
      "source": [
        "#Logistic regression model implementation\n",
        "# Train different models and evaluate their accuracy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "degree = [2,3,7]\n",
        "for i in degree:\n",
        "    lg_model = make_pipeline(PolynomialFeatures(i), LogisticRegression(C=1.0, solver='saga', max_iter=100))\n",
        "    # Compute cross-validation scores\n",
        "    cv_scores = cross_val_score(lg_model, X_train, y_train, cv=5)\n",
        "    print(f\"Model: Logistic regression\")\n",
        "    print(f\"Cross-validation scores: {cv_scores}\")\n",
        "    print(f\"Mean cross-validation score: {np.mean(cv_scores)}\\n\")\n",
        "    # Fit the model on the training data\n",
        "    lg_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the validation data\n",
        "    y_val_pred = lg_model.predict(X_val)\n",
        "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "    val_class_report = classification_report(y_val, y_val_pred)\n",
        "    val_conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
        "\n",
        "    print(f\"Model: Logistic Regression\")\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "    print(\"Validation Classification Report:\")\n",
        "    print(val_class_report)\n",
        "    print(\"Validation Confusion Matrix:\")\n",
        "    print(val_conf_matrix)\n",
        "    print()\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_test_pred = lg_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    test_class_report = classification_report(y_test, y_test_pred)\n",
        "    test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "    print(\"Test Classification Report:\")\n",
        "    print(test_class_report)\n",
        "    print(\"Test Confusion Matrix:\")\n",
        "    print(test_conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnYx_zYnEvD-",
        "outputId": "896a1dcf-819d-4ec9-a3c5-476eb2ff940e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Decision Tree\n",
            "Cross-validation scores: [0.89912568 0.8986484  0.89824766 0.89784692 0.89784692]\n",
            "Mean cross-validation score: 0.8983431154090636\n",
            "\n",
            "Model: Logistic Regression\n",
            "Validation Accuracy: 0.90\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.67      0.74      1819\n",
            "           1       0.00      0.00      0.00       928\n",
            "           2       0.96      1.00      0.98      7789\n",
            "           3       0.83      1.00      0.91      4714\n",
            "\n",
            "    accuracy                           0.90     15250\n",
            "   macro avg       0.65      0.67      0.66     15250\n",
            "weighted avg       0.85      0.90      0.87     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[1217    0    0  602]\n",
            " [ 269    0  316  343]\n",
            " [   0    0 7789    0]\n",
            " [   3    0    0 4711]]\n",
            "\n",
            "Test Accuracy: 0.89\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.66      0.73      4741\n",
            "           1       0.00      0.00      0.00      2369\n",
            "           2       0.96      1.00      0.98     19169\n",
            "           3       0.82      1.00      0.90     11845\n",
            "\n",
            "    accuracy                           0.89     38124\n",
            "   macro avg       0.65      0.66      0.65     38124\n",
            "weighted avg       0.84      0.89      0.86     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 3118     0     0  1623]\n",
            " [  671     0   800   898]\n",
            " [    0     0 19169     0]\n",
            " [   16     0     0 11829]]\n",
            "Model: Decision Tree\n",
            "Cross-validation scores: [0.90313297 0.90221866 0.90236438 0.90207294 0.90163576]\n",
            "Mean cross-validation score: 0.9022849420163283\n",
            "\n",
            "Model: Logistic Regression\n",
            "Validation Accuracy: 0.91\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.66      0.73      1819\n",
            "           1       0.65      0.20      0.31       928\n",
            "           2       0.97      1.00      0.98      7789\n",
            "           3       0.85      0.99      0.91      4714\n",
            "\n",
            "    accuracy                           0.91     15250\n",
            "   macro avg       0.82      0.71      0.73     15250\n",
            "weighted avg       0.89      0.91      0.89     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[1196   30    0  593]\n",
            " [ 240  186  270  232]\n",
            " [   0   17 7772    0]\n",
            " [   5   55    0 4654]]\n",
            "\n",
            "Test Accuracy: 0.90\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.65      0.73      4741\n",
            "           1       0.63      0.18      0.28      2369\n",
            "           2       0.96      1.00      0.98     19169\n",
            "           3       0.84      0.99      0.91     11845\n",
            "\n",
            "    accuracy                           0.90     38124\n",
            "   macro avg       0.82      0.70      0.72     38124\n",
            "weighted avg       0.89      0.90      0.88     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 3066    75     0  1600]\n",
            " [  591   420   706   652]\n",
            " [    0    50 19119     0]\n",
            " [   12   123     0 11710]]\n",
            "Model: Decision Tree\n",
            "Cross-validation scores: [0.8947541  0.89365733 0.89358447 0.89566104 0.89434952]\n",
            "Mean cross-validation score: 0.894401291456167\n",
            "\n",
            "Model: Logistic Regression\n",
            "Validation Accuracy: 0.90\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.65      0.72      1819\n",
            "           1       0.55      0.28      0.37       928\n",
            "           2       0.97      0.99      0.98      7789\n",
            "           3       0.85      0.96      0.90      4714\n",
            "\n",
            "    accuracy                           0.90     15250\n",
            "   macro avg       0.79      0.72      0.74     15250\n",
            "weighted avg       0.89      0.90      0.89     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[1187   80    0  552]\n",
            " [ 202  258  250  218]\n",
            " [   0   45 7744    0]\n",
            " [  99   86    0 4529]]\n",
            "\n",
            "Test Accuracy: 0.89\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.65      0.71      4741\n",
            "           1       0.55      0.23      0.33      2369\n",
            "           2       0.97      0.99      0.98     19169\n",
            "           3       0.84      0.97      0.90     11845\n",
            "\n",
            "    accuracy                           0.89     38124\n",
            "   macro avg       0.79      0.71      0.73     38124\n",
            "weighted avg       0.88      0.89      0.88     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 3072   170     0  1499]\n",
            " [  548   549   669   603]\n",
            " [    0   113 19056     0]\n",
            " [  239   171     0 11435]]\n",
            "Model: Decision Tree\n",
            "Cross-validation scores: [0.88546448 0.88134358 0.8839302  0.88513243 0.8839302 ]\n",
            "Mean cross-validation score: 0.8839601773144313\n",
            "\n",
            "Model: Logistic Regression\n",
            "Validation Accuracy: 0.89\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.67      0.70      1819\n",
            "           1       0.48      0.30      0.37       928\n",
            "           2       0.97      0.99      0.98      7789\n",
            "           3       0.86      0.92      0.89      4714\n",
            "\n",
            "    accuracy                           0.89     15250\n",
            "   macro avg       0.76      0.72      0.74     15250\n",
            "weighted avg       0.88      0.89      0.88     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[1220  110    0  489]\n",
            " [ 199  280  243  206]\n",
            " [   0   67 7722    0]\n",
            " [ 233  124    0 4357]]\n",
            "\n",
            "Test Accuracy: 0.89\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.67      0.70      4741\n",
            "           1       0.46      0.26      0.33      2369\n",
            "           2       0.97      0.99      0.98     19169\n",
            "           3       0.85      0.93      0.89     11845\n",
            "\n",
            "    accuracy                           0.89     38124\n",
            "   macro avg       0.76      0.71      0.72     38124\n",
            "weighted avg       0.87      0.89      0.88     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 3168   252     0  1321]\n",
            " [  559   610   656   544]\n",
            " [    0   181 18988     0]\n",
            " [  580   274     0 10991]]\n"
          ]
        }
      ],
      "source": [
        "# decision tree implementation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "depth = [5,10,15,20]\n",
        "for i in depth:\n",
        "    dt_model = DecisionTreeClassifier(max_depth=i, min_samples_split=5, min_samples_leaf=2)\n",
        "    # Compute cross-validation scores\n",
        "    cv_scores = cross_val_score(dt_model, X_train, y_train, cv=5)\n",
        "    print(f\"Model: Decision Tree\")\n",
        "    print(f\"Cross-validation scores: {cv_scores}\")\n",
        "    print(f\"Mean cross-validation score: {np.mean(cv_scores)}\\n\")\n",
        "    # Fit the model on the training data\n",
        "    dt_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the validation data\n",
        "    y_val_pred = dt_model.predict(X_val)\n",
        "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "    val_class_report = classification_report(y_val, y_val_pred)\n",
        "    val_conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
        "\n",
        "    print(f\"Model: Logistic Regression\")\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "    print(\"Validation Classification Report:\")\n",
        "    print(val_class_report)\n",
        "    print(\"Validation Confusion Matrix:\")\n",
        "    print(val_conf_matrix)\n",
        "    print()\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_test_pred = dt_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    test_class_report = classification_report(y_test, y_test_pred)\n",
        "    test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "    print(\"Test Classification Report:\")\n",
        "    print(test_class_report)\n",
        "    print(\"Test Confusion Matrix:\")\n",
        "    print(test_conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsbMVu8MGTJV",
        "outputId": "077f3824-7080-4fb5-9d55-318050c059c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparison of Best Validation Accuracy for Each Parameter Grid:\n",
            "      param_set  mean_test_score\n",
            "0  param_grid_1         0.904443\n",
            "1  param_grid_2         0.905342\n",
            "2  param_grid_3         0.904929\n",
            "3  param_grid_4         0.904863\n",
            "\n",
            "Best parameters and their scores for each parameter grid:\n",
            "param_grid_1: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200} with best validation accuracy: 0.9044\n",
            "param_grid_2: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 120} with best validation accuracy: 0.9053\n",
            "param_grid_3: {'max_depth': 12, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 150} with best validation accuracy: 0.9049\n",
            "param_grid_4: {'max_depth': 18, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 160} with best validation accuracy: 0.9049\n",
            "\n",
            "Best parameter set overall: param_grid_2\n",
            "Best cross-validation score: 0.9053\n",
            "Best parameters found: {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 120}\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 3072    71     0  1598]\n",
            " [  567   447   698   657]\n",
            " [    0    51 19118     0]\n",
            " [   36    80     0 11729]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.65      0.73      4741\n",
            "           1       0.69      0.19      0.30      2369\n",
            "           2       0.96      1.00      0.98     19169\n",
            "           3       0.84      0.99      0.91     11845\n",
            "\n",
            "    accuracy                           0.90     38124\n",
            "   macro avg       0.83      0.71      0.73     38124\n",
            "weighted avg       0.89      0.90      0.88     38124\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Random forest implementation\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assume X and y are your features and target variables\n",
        "# X, y = your_data_features, your_data_target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grids\n",
        "param_grids = [\n",
        "    {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    },\n",
        "    {\n",
        "        'n_estimators': [30, 60, 120],\n",
        "        'max_depth': [None, 7, 14],\n",
        "        'min_samples_split': [4, 8, 12],\n",
        "        'min_samples_leaf': [2, 4, 6]\n",
        "    },\n",
        "    {\n",
        "        'n_estimators': [25, 75, 150],\n",
        "        'max_depth': [None, 12, 25],\n",
        "        'min_samples_split': [2, 6, 10],\n",
        "        'min_samples_leaf': [1, 3, 5]\n",
        "    },\n",
        "    {\n",
        "        'n_estimators': [40, 80, 160],\n",
        "        'max_depth': [None, 6, 18],\n",
        "        'min_samples_split': [3, 5, 9],\n",
        "        'min_samples_leaf': [1, 3, 4]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Initialize a RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Function to perform grid search and return results\n",
        "def perform_grid_search(param_grid, X_train, y_train):\n",
        "    grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "    return results_df, grid_search\n",
        "\n",
        "# Store results for comparison\n",
        "results_list = []\n",
        "grid_search_objects = []\n",
        "best_params_list = []\n",
        "\n",
        "# Perform grid search for each parameter grid\n",
        "for i, param_grid in enumerate(param_grids):\n",
        "    results_df, grid_search = perform_grid_search(param_grid, X_train, y_train)\n",
        "    results_df['param_set'] = f'param_grid_{i + 1}'\n",
        "    results_list.append(results_df)\n",
        "    grid_search_objects.append(grid_search)\n",
        "    best_params_list.append((grid_search.best_params_, grid_search.best_score_, f'param_grid_{i + 1}'))\n",
        "\n",
        "# Concatenate results\n",
        "all_results_df = pd.concat(results_list, ignore_index=True)\n",
        "\n",
        "# Extract best scores for each parameter grid\n",
        "best_scores = all_results_df.groupby('param_set')['mean_test_score'].max().reset_index()\n",
        "\n",
        "# Print the results\n",
        "print(\"Comparison of Best Validation Accuracy for Each Parameter Grid:\")\n",
        "print(best_scores)\n",
        "\n",
        "# Print the best parameters and their scores for each parameter grid\n",
        "print(\"\\nBest parameters and their scores for each parameter grid:\")\n",
        "for best_params, best_score, param_set in best_params_list:\n",
        "    print(f\"{param_set}: {best_params} with best validation accuracy: {best_score:.4f}\")\n",
        "\n",
        "# Identify the best parameter grid overall\n",
        "best_param_set = best_scores.loc[best_scores['mean_test_score'].idxmax()]\n",
        "\n",
        "print(f\"\\nBest parameter set overall: {best_param_set['param_set']}\")\n",
        "print(f\"Best cross-validation score: {best_param_set['mean_test_score']:.4f}\")\n",
        "\n",
        "# Get the best GridSearchCV object\n",
        "best_grid_search = grid_search_objects[int(best_param_set['param_set'].split('_')[-1]) - 1]\n",
        "\n",
        "# Extract the best parameters\n",
        "best_params = best_grid_search.best_params_\n",
        "print(f\"Best parameters found: {best_params}\")\n",
        "\n",
        "# Train the best model on the entire training set using the best parameter set\n",
        "best_rf_model = best_grid_search.best_estimator_\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Generate classification report\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0fFY0k_GdkN",
        "outputId": "41b685b4-1c81-4b92-9394-b6973ee2c7e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: DecisionTreeClassifier\n",
            "Cross-validation scores: [0.90229508 0.90268533 0.90445588 0.90393128 0.90209515]\n",
            "Mean cross-validation score: 0.9030925453616054\n",
            "\n",
            "Model: DecisionTreeClassifier\n",
            "Validation Accuracy: 0.91\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.66      0.74      1819\n",
            "           1       0.73      0.25      0.37       928\n",
            "           2       0.97      1.00      0.98      7789\n",
            "           3       0.85      0.99      0.92      4714\n",
            "\n",
            "    accuracy                           0.91     15250\n",
            "   macro avg       0.85      0.72      0.75     15250\n",
            "weighted avg       0.90      0.91      0.90     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[1192   34    0  593]\n",
            " [ 208  229  262  229]\n",
            " [   0   16 7773    0]\n",
            " [   4   36    0 4674]]\n",
            "\n",
            "Test Accuracy: 0.90\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.64      0.72      4741\n",
            "           1       0.61      0.19      0.29      2369\n",
            "           2       0.96      1.00      0.98     19169\n",
            "           3       0.84      0.99      0.91     11845\n",
            "\n",
            "    accuracy                           0.90     38124\n",
            "   macro avg       0.81      0.70      0.73     38124\n",
            "weighted avg       0.89      0.90      0.88     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 3015   117     0  1609]\n",
            " [  546   459   702   662]\n",
            " [    0    61 19108     0]\n",
            " [   18   113     0 11714]]\n",
            "\n",
            "Model: RandomForestClassifier\n",
            "Cross-validation scores: [0.90311475 0.90245582 0.90406243 0.90498049 0.90166891]\n",
            "Mean cross-validation score: 0.9032564797878351\n",
            "\n",
            "Model: RandomForestClassifier\n",
            "Validation Accuracy: 0.91\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.67      0.74      1819\n",
            "           1       0.81      0.14      0.24       928\n",
            "           2       0.96      1.00      0.98      7789\n",
            "           3       0.85      1.00      0.92      4714\n",
            "\n",
            "    accuracy                           0.91     15250\n",
            "   macro avg       0.86      0.70      0.72     15250\n",
            "weighted avg       0.90      0.91      0.89     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[1216    7    0  596]\n",
            " [ 251  131  292  254]\n",
            " [   0    5 7784    0]\n",
            " [   1   19    0 4694]]\n",
            "\n",
            "Test Accuracy: 0.90\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.65      0.73      4741\n",
            "           1       0.74      0.11      0.20      2369\n",
            "           2       0.96      1.00      0.98     19169\n",
            "           3       0.84      0.99      0.91     11845\n",
            "\n",
            "    accuracy                           0.90     38124\n",
            "   macro avg       0.84      0.69      0.70     38124\n",
            "weighted avg       0.89      0.90      0.88     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 3100    26     0  1615]\n",
            " [  625   272   763   709]\n",
            " [    0     9 19160     0]\n",
            " [    9    60     0 11776]]\n",
            "\n",
            "Logistic Regression with Polynomial Degree 2\n",
            "Cross-validation scores: [0.73701639 0.7325814  0.73245024 0.73648316 0.73363061]\n",
            "Mean cross-validation score: 0.7344323616092762\n",
            "\n",
            "Logistic Regression with Polynomial Degree 2\n",
            "Validation Accuracy: 0.74\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.05      0.09      1819\n",
            "           1       0.47      0.01      0.02       928\n",
            "           2       0.76      0.92      0.83      7789\n",
            "           3       0.73      0.83      0.78      4714\n",
            "\n",
            "    accuracy                           0.74     15250\n",
            "   macro avg       0.55      0.45      0.43     15250\n",
            "weighted avg       0.67      0.74      0.68     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[  94    8 1051  666]\n",
            " [  40    8  493  387]\n",
            " [ 218    1 7203  367]\n",
            " [  27    0  753 3934]]\n",
            "\n",
            "Logistic Regression with Polynomial Degree 2\n",
            "Test Accuracy: 0.73\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.04      0.07      4741\n",
            "           1       0.49      0.01      0.02      2369\n",
            "           2       0.75      0.92      0.83     19169\n",
            "           3       0.73      0.84      0.78     11845\n",
            "\n",
            "    accuracy                           0.73     38124\n",
            "   macro avg       0.55      0.45      0.43     38124\n",
            "weighted avg       0.66      0.73      0.67     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[  197    23  2817  1704]\n",
            " [   77    26  1279   987]\n",
            " [  561     4 17687   917]\n",
            " [   57     0  1842  9946]]\n",
            "Logistic Regression with Polynomial Degree 3\n",
            "Cross-validation scores: [0.69911475 0.69703925 0.69835077 0.70126889 0.6928096 ]\n",
            "Mean cross-validation score: 0.697716652252506\n",
            "\n",
            "Logistic Regression with Polynomial Degree 3\n",
            "Validation Accuracy: 0.71\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.02      0.04      1819\n",
            "           1       0.33      0.00      0.00       928\n",
            "           2       0.69      0.96      0.81      7789\n",
            "           3       0.77      0.69      0.73      4714\n",
            "\n",
            "    accuracy                           0.71     15250\n",
            "   macro avg       0.50      0.42      0.40     15250\n",
            "weighted avg       0.64      0.71      0.64     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[  43    3 1317  456]\n",
            " [  25    2  548  353]\n",
            " [ 161    1 7488  139]\n",
            " [   1    0 1451 3262]]\n",
            "\n",
            "Logistic Regression with Polynomial Degree 3\n",
            "Test Accuracy: 0.70\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.17      0.02      0.04      4741\n",
            "           1       0.36      0.00      0.00      2369\n",
            "           2       0.68      0.95      0.80     19169\n",
            "           3       0.77      0.70      0.73     11845\n",
            "\n",
            "    accuracy                           0.70     38124\n",
            "   macro avg       0.50      0.42      0.39     38124\n",
            "weighted avg       0.63      0.70      0.63     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[  106     5  3439  1191]\n",
            " [   41     4  1434   890]\n",
            " [  478     2 18296   393]\n",
            " [    4     0  3552  8289]]\n",
            "Logistic Regression with Polynomial Degree 4\n",
            "Cross-validation scores: [0.66481967 0.66202171 0.66195613 0.66539887 0.65952982]\n",
            "Mean cross-validation score: 0.6627452387312888\n",
            "\n",
            "Logistic Regression with Polynomial Degree 4\n",
            "Validation Accuracy: 0.67\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.05      0.00      0.00      1819\n",
            "           1       0.00      0.00      0.00       928\n",
            "           2       0.65      0.97      0.78      7789\n",
            "           3       0.78      0.57      0.66      4714\n",
            "\n",
            "    accuracy                           0.67     15250\n",
            "   macro avg       0.37      0.39      0.36     15250\n",
            "weighted avg       0.58      0.67      0.60     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[   4    0 1521  294]\n",
            " [   4    0  598  326]\n",
            " [  61    2 7593  133]\n",
            " [   4    0 2036 2674]]\n",
            "\n",
            "Logistic Regression with Polynomial Degree 4\n",
            "Test Accuracy: 0.67\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.07      0.00      0.01      4741\n",
            "           1       0.00      0.00      0.00      2369\n",
            "           2       0.64      0.97      0.77     19169\n",
            "           3       0.78      0.58      0.66     11845\n",
            "\n",
            "    accuracy                           0.67     38124\n",
            "   macro avg       0.37      0.39      0.36     38124\n",
            "weighted avg       0.57      0.67      0.59     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[   14     0  3980   747]\n",
            " [    4     0  1568   797]\n",
            " [  168     4 18629   368]\n",
            " [   14     0  4997  6834]]\n",
            "Logistic Regression with Polynomial Degree 5\n",
            "Cross-validation scores: [0.64708197 0.6437916  0.64372602 0.64818519 0.64175875]\n",
            "Mean cross-validation score: 0.6449087046659419\n",
            "\n",
            "Logistic Regression with Polynomial Degree 5\n",
            "Validation Accuracy: 0.65\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      0.01      0.01      1819\n",
            "           1       0.00      0.00      0.00       928\n",
            "           2       0.63      0.97      0.76      7789\n",
            "           3       0.79      0.50      0.62      4714\n",
            "\n",
            "    accuracy                           0.65     15250\n",
            "   macro avg       0.38      0.37      0.35     15250\n",
            "weighted avg       0.58      0.65      0.58     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[  14    0 1579  226]\n",
            " [  14    0  630  284]\n",
            " [  93    0 7588  108]\n",
            " [  19    0 2319 2376]]\n",
            "\n",
            "Logistic Regression with Polynomial Degree 5\n",
            "Test Accuracy: 0.65\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.01      0.01      4741\n",
            "           1       0.00      0.00      0.00      2369\n",
            "           2       0.62      0.97      0.76     19169\n",
            "           3       0.79      0.51      0.62     11845\n",
            "\n",
            "    accuracy                           0.65     38124\n",
            "   macro avg       0.37      0.37      0.35     38124\n",
            "weighted avg       0.57      0.65      0.58     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[   30     0  4112   599]\n",
            " [   20     0  1634   715]\n",
            " [  266     0 18605   298]\n",
            " [   51     0  5707  6087]]\n",
            "Logistic Regression with Polynomial Degree 6\n",
            "Cross-validation scores: [0.62088525 0.60742975 0.61510213 0.61880717 0.61565953]\n",
            "Mean cross-validation score: 0.6155767672038697\n",
            "\n",
            "Logistic Regression with Polynomial Degree 6\n",
            "Validation Accuracy: 0.62\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.21      0.22      1819\n",
            "           1       0.00      0.00      0.00       928\n",
            "           2       0.64      0.88      0.74      7789\n",
            "           3       0.80      0.46      0.59      4714\n",
            "\n",
            "    accuracy                           0.62     15250\n",
            "   macro avg       0.42      0.39      0.39     15250\n",
            "weighted avg       0.60      0.62      0.59     15250\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "[[ 385    0 1242  192]\n",
            " [  87    0  573  268]\n",
            " [ 828    0 6880   81]\n",
            " [ 438    0 2097 2179]]\n",
            "\n",
            "Logistic Regression with Polynomial Degree 6\n",
            "Test Accuracy: 0.61\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.19      0.20      4741\n",
            "           1       0.00      0.00      0.00      2369\n",
            "           2       0.63      0.88      0.73     19169\n",
            "           3       0.79      0.46      0.59     11845\n",
            "\n",
            "    accuracy                           0.61     38124\n",
            "   macro avg       0.41      0.38      0.38     38124\n",
            "weighted avg       0.59      0.61      0.57     38124\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[  897     0  3346   498]\n",
            " [  228     0  1473   668]\n",
            " [ 2043     0 16871   255]\n",
            " [ 1110     0  5246  5489]]\n"
          ]
        }
      ],
      "source": [
        "#from sklearn.model_selection import cross_val_score\n",
        "\n",
        "degree = [2, 3, 4, 5, 6, 7]\n",
        "\n",
        "# Define models with hyperparameters\n",
        "models = [\n",
        "    DecisionTreeClassifier(max_depth=10, min_samples_split=5, min_samples_leaf=2),\n",
        "    RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5, min_samples_leaf=2),\n",
        "]\n",
        "\n",
        "# Fit and evaluate each model\n",
        "for model in models:\n",
        "    # Compute cross-validation scores\n",
        "    try:\n",
        "        cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "        print(f\"Model: {model.__class__.__name__}\")\n",
        "        print(f\"Cross-validation scores: {cv_scores}\")\n",
        "        print(f\"Mean cross-validation score: {np.mean(cv_scores)}\\n\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error in model {model.__class__.__name__}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the validation data\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "    val_class_report = classification_report(y_val, y_val_pred)\n",
        "    val_conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
        "\n",
        "    print(f\"Model: {model.__class__.__name__}\")\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "    print(\"Validation Classification Report:\")\n",
        "    print(val_class_report)\n",
        "    print(\"Validation Confusion Matrix:\")\n",
        "    print(val_conf_matrix)\n",
        "    print()\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    test_class_report = classification_report(y_test, y_test_pred)\n",
        "    test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "    print(\"Test Classification Report:\")\n",
        "    print(test_class_report)\n",
        "    print(\"Test Confusion Matrix:\")\n",
        "    print(test_conf_matrix)\n",
        "    print()\n",
        "\n",
        "# Evaluate Logistic Regression with Polynomial Features separately\n",
        "for deg in degree:\n",
        "    lg_model = make_pipeline(PolynomialFeatures(deg), LogisticRegression(C=1.0, solver='saga', max_iter=200))\n",
        "\n",
        "    try:\n",
        "        cv_scores = cross_val_score(lg_model, X_train, y_train, cv=5)\n",
        "        print(f\"Logistic Regression with Polynomial Degree {deg}\")\n",
        "        print(f\"Cross-validation scores: {cv_scores}\")\n",
        "        print(f\"Mean cross-validation score: {np.mean(cv_scores)}\\n\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error in Logistic Regression with Polynomial Degree {deg}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    lg_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the validation data\n",
        "    y_val_pred = lg_model.predict(X_val)\n",
        "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "    val_class_report = classification_report(y_val, y_val_pred)\n",
        "    val_conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
        "\n",
        "    print(f\"Logistic Regression with Polynomial Degree {deg}\")\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "    print(\"Validation Classification Report:\")\n",
        "    print(val_class_report)\n",
        "    print(\"Validation Confusion Matrix:\")\n",
        "    print(val_conf_matrix)\n",
        "    print()\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_test_pred = lg_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    test_class_report = classification_report(y_test, y_test_pred)\n",
        "    test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"Logistic Regression with Polynomial Degree {deg}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "    print(\"Test Classification Report:\")\n",
        "    print(test_class_report)\n",
        "    print(\"Test Confusion Matrix:\")\n",
        "    print(test_conf_matrix)\n",
        "    #print()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}